{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch \n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, GPTNeoForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.cuda.device at 0x7fd17be2c0d0>,\n",
       " <torch.cuda.device at 0x7fd179c7ee30>,\n",
       " <torch.cuda.device at 0x7fd1783fd7e0>,\n",
       " <torch.cuda.device at 0x7fd1783fdd50>,\n",
       " <torch.cuda.device at 0x7fd1783fd390>,\n",
       " <torch.cuda.device at 0x7fd1783fddb0>,\n",
       " <torch.cuda.device at 0x7fd1783fd570>,\n",
       " <torch.cuda.device at 0x7fd022ce1ff0>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "available_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name_or_path = \"princeton-nlp/Sheared-LLaMA-1.3B\"\n",
    "\n",
    "# model_name_or_path = \"meta-llama/Llama-2-7b-hf\"\n",
    "# model_name_or_path = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "model_name_or_path = \"mistralai/Mistral-7B-v0.1\"\n",
    "# model_name_or_path = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "# model_name_or_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change cach dir for models\n",
    "CACHE_DIR = \"/data/pre-trained-models-cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81096d90739a48c6adfa7af41b76ba0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, token=token)\n",
    "attn_implementation = 'eager'\n",
    "lm = AutoModelForCausalLM.from_pretrained(model_name_or_path, token=token, cache_dir=CACHE_DIR, attn_implementation=attn_implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load LLM2Vec transformed model\n",
    "# attn_implementation='flash_attention_2'\n",
    "# lm = AutoModelForCausalLM.from_pretrained('vaibhavad/mistral-enc', torch_dtype=torch.bfloat16, cache_dir=CACHE_DIR, attn_implementation=attn_implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if attn_implementation == 'flash_attention_2':\n",
    "    tokenizer.padding_side  = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralConfig {\n",
       "  \"_name_or_path\": \"mistralai/Mistral-7B-v0.1\",\n",
       "  \"architectures\": [\n",
       "    \"MistralForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 14336,\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"model_type\": \"mistral\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"sliding_window\": 4096,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.39.0.dev0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_prefix, text = 'Montreal', \"Montreal is the second most populous city in Canada, the tenth most populous city in North America, and the most populous city in the province of Quebec. Founded in 1642 as Ville-Marie, or 'City of Mary', it is named after Mount Royal, the triple-peaked hill around which the early city of Ville-Marie was built. The city is centred on the Island of Montreal, which obtained its name from the same origin as the city, and a few much smaller peripheral islands, the largest of which is Île Bizard. The city is 196 km (122 mi) east of the national capital, Ottawa, and 258 km (160 mi) southwest of the provincial capital, Quebec City.\"\n",
    "# output_prefix, text = 'Philadelphia', \"Philadelphia, commonly referred to as Philly, is the most populous city in the U.S. state of Pennsylvania and the second-most populous city in the Northeast megalopolis and Mid-Atlantic regions after New York City. Philadelphia is known for its extensive contributions to United States history, especially the American Revolution, and served as the nation's capital until 1800. It maintains contemporary influence in business and industry, culture, sports, and music. Philadelphia is the nation's sixth-most populous city, with a population of 1,603,797 in the 2020 census and is the urban core of the larger Delaware Valley (or Philadelphia metropolitan area), the nation's seventh-largest and one of the world's largest metropolitan regions consisting of 6.245 million residents in the metropolitan statistical area and 7.366 million residents in its combined statistical area.\"\n",
    "output_prefix, text = \"Baltimore\", \"Baltimore is the most populous city in the U.S. state of Maryland. With a population of 585,708 at the 2020 census, it is the 30th-most populous city in the United States. Baltimore was designated an independent city by the Constitution of Maryland in 1851, and is currently the most populous independent city in the nation. As of the 2020 census, the population of the Baltimore metropolitan area was estimated to be 2,838,327, making it the 20th-largest metropolitan area in the country. When combined with the larger Washington metropolitan area, the Washington–Baltimore combined statistical area (CSA) has a 2020 U.S. census population of 9,973,383, the third-largest in the country.\"\n",
    "# output_prefix, text = \"\", \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left\n",
      "194\n",
      "torch.Size([1, 194])\n",
      "tensor([[    1, 23349,   349,   272,  1080,  1852,  9504,  2990,   297,   272,\n",
      "           500, 28723, 28735, 28723,  1665,   302, 20261, 28723,  2326,   264,\n",
      "          4889,   302, 28705, 28782, 28783, 28782, 28725, 28787, 28734, 28783,\n",
      "           438,   272, 28705, 28750, 28734, 28750, 28734, 21254, 28725,   378,\n",
      "           349,   272, 28705, 28770, 28734,   362, 28733,  2284,  1852,  9504,\n",
      "          2990,   297,   272,  2969,  3543, 28723, 23349,   403, 20444,   396,\n",
      "          7126,  2990,   486,   272, 18620,   302, 20261,   297, 28705, 28740,\n",
      "         28783, 28782, 28740, 28725,   304,   349,  5489,   272,  1080,  1852,\n",
      "          9504,  7126,  2990,   297,   272,  5878, 28723,  1136,   302,   272,\n",
      "         28705, 28750, 28734, 28750, 28734, 21254, 28725,   272,  4889,   302,\n",
      "           272, 23349,  1424, 22159,  2698,   403, 11909,   298,   347, 28705,\n",
      "         28750, 28725, 28783, 28770, 28783, 28725, 28770, 28750, 28787, 28725,\n",
      "          2492,   378,   272, 28705, 28750, 28734,   362, 28733, 20832,   374,\n",
      "          1424, 22159,  2698,   297,   272,  2939, 28723,  1684,  9837,   395,\n",
      "           272,  6084,  5924,  1424, 22159,  2698, 28725,   272,  5924, 28816,\n",
      "         28760,  2304, 20481,  9837, 21256,  2698,   325, 28743,  5530, 28731,\n",
      "           659,   264, 28705, 28750, 28734, 28750, 28734,   500, 28723, 28735,\n",
      "         28723, 21254,  4889,   302, 28705, 28774, 28725, 28774, 28787, 28770,\n",
      "         28725, 28770, 28783, 28770, 28725,   272,  4008, 28733, 20832,   374,\n",
      "           297,   272,  2939, 28723]])\n",
      "['<s>', '▁Baltimore', '▁is', '▁the', '▁most', '▁pop', 'ulous', '▁city', '▁in', '▁the', '▁U', '.', 'S', '.', '▁state', '▁of', '▁Maryland', '.', '▁With', '▁a', '▁population', '▁of', '▁', '5', '8', '5', ',', '7', '0', '8', '▁at', '▁the', '▁', '2', '0', '2', '0', '▁census', ',', '▁it', '▁is', '▁the', '▁', '3', '0', 'th', '-', 'most', '▁pop', 'ulous', '▁city', '▁in', '▁the', '▁United', '▁States', '.', '▁Baltimore', '▁was', '▁designated', '▁an', '▁independent', '▁city', '▁by', '▁the', '▁Constitution', '▁of', '▁Maryland', '▁in', '▁', '1', '8', '5', '1', ',', '▁and', '▁is', '▁currently', '▁the', '▁most', '▁pop', 'ulous', '▁independent', '▁city', '▁in', '▁the', '▁nation', '.', '▁As', '▁of', '▁the', '▁', '2', '0', '2', '0', '▁census', ',', '▁the', '▁population', '▁of', '▁the', '▁Baltimore', '▁met', 'ropolitan', '▁area', '▁was', '▁estimated', '▁to', '▁be', '▁', '2', ',', '8', '3', '8', ',', '3', '2', '7', ',', '▁making', '▁it', '▁the', '▁', '2', '0', 'th', '-', 'larg', 'est', '▁met', 'ropolitan', '▁area', '▁in', '▁the', '▁country', '.', '▁When', '▁combined', '▁with', '▁the', '▁larger', '▁Washington', '▁met', 'ropolitan', '▁area', ',', '▁the', '▁Washington', '–', 'B', 'alt', 'imore', '▁combined', '▁statistical', '▁area', '▁(', 'C', 'SA', ')', '▁has', '▁a', '▁', '2', '0', '2', '0', '▁U', '.', 'S', '.', '▁census', '▁population', '▁of', '▁', '9', ',', '9', '7', '3', ',', '3', '8', '3', ',', '▁the', '▁third', '-', 'larg', 'est', '▁in', '▁the', '▁country', '.']\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer.encode(text, padding=\"do_not_pad\")\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "seq_len = len(tokens)\n",
    "input_ids = torch.tensor(ids).reshape(1, -1)\n",
    "print(tokenizer.padding_side)\n",
    "print(seq_len)\n",
    "print(input_ids.shape)\n",
    "print(input_ids)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
       "         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
       "         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset = 0\n",
    "# offset = 4096 # TODO(mm): using any offset here results in CUDA errors. Try to figure out why.\n",
    "position_ids = torch.arange(start=offset, end=seq_len + offset).view(1, seq_len)\n",
    "position_ids.shape\n",
    "position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_type = \"causal\"\n",
    "# attention_type = \"bidirectional\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable bidirectional attention\n",
    "attention_mask = None\n",
    "if attention_type == \"bidirectional\":\n",
    "    # construct attention mask (batch_size, 1, seq_len, seq_len)\n",
    "    attention_mask = torch.ones(size=(1, 1, seq_len, seq_len)).to(device)\n",
    "\n",
    "    if model_name_or_path in [\"princeton-nlp/Sheared-LLaMA-1.3B\", \"meta-llama/Llama-2-7b-hf\", \"meta-llama/Llama-2-7b-chat-hf\"]:\n",
    "        lm.model._update_causal_mask = lambda attention_mask, _: attention_mask\n",
    "\n",
    "    if model_name_or_path == \"EleutherAI/gpt-neo-1.3B\":\n",
    "        gpt_neo_max_length = 2048\n",
    "        bi_mask = torch.ones((1, 1, gpt_neo_max_length, gpt_neo_max_length), dtype=bool)\n",
    "\n",
    "        # overwrite causal mask at every layer\n",
    "        for lidx in range(len(lm.transformer.h)):\n",
    "            lm.transformer.h[lidx].attn.attention.bias = bi_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put inputs and model on GPU\n",
    "lm.to(device)\n",
    "input_ids = input_ids.to(device)\n",
    "position_ids = position_ids.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 194])\n",
      "torch.Size([1, 194])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids.shape)\n",
    "print(position_ids.shape)\n",
    "# print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = input_ids\n",
    "output = lm.forward(input_ids=input_ids, position_ids=position_ids, labels=labels, attention_mask=attention_mask, output_attentions=True, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# look at attention matrices\n",
    "# A = output.attentions[-1].squeeze()[-1]\n",
    "A = output.attentions[-1].squeeze()[-1].detach().cpu().float().numpy() \n",
    "print(np.triu(A, k=1)) # the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7626, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([194, 32000])\n"
     ]
    }
   ],
   "source": [
    "logits = output.logits.squeeze()\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([194])\n"
     ]
    }
   ],
   "source": [
    "preds = torch.argmax(logits, dim=1)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_tokens = tokenizer.convert_ids_to_tokens(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '▁Baltimore',\n",
       " '▁is',\n",
       " '▁the',\n",
       " '▁most',\n",
       " '▁pop',\n",
       " 'ulous',\n",
       " '▁city',\n",
       " '▁in',\n",
       " '▁the',\n",
       " '▁U',\n",
       " '.',\n",
       " 'S',\n",
       " '.',\n",
       " '▁state',\n",
       " '▁of',\n",
       " '▁Maryland',\n",
       " '.',\n",
       " '▁With',\n",
       " '▁a',\n",
       " '▁population',\n",
       " '▁of',\n",
       " '▁',\n",
       " '5',\n",
       " '8',\n",
       " '5',\n",
       " ',',\n",
       " '7',\n",
       " '0',\n",
       " '8',\n",
       " '▁at',\n",
       " '▁the',\n",
       " '▁',\n",
       " '2',\n",
       " '0',\n",
       " '2',\n",
       " '0',\n",
       " '▁census',\n",
       " ',',\n",
       " '▁it',\n",
       " '▁is',\n",
       " '▁the',\n",
       " '▁',\n",
       " '3',\n",
       " '0',\n",
       " 'th',\n",
       " '-',\n",
       " 'most',\n",
       " '▁pop',\n",
       " 'ulous',\n",
       " '▁city',\n",
       " '▁in',\n",
       " '▁the',\n",
       " '▁United',\n",
       " '▁States',\n",
       " '.',\n",
       " '▁Baltimore',\n",
       " '▁was',\n",
       " '▁designated',\n",
       " '▁an',\n",
       " '▁independent',\n",
       " '▁city',\n",
       " '▁by',\n",
       " '▁the',\n",
       " '▁Constitution',\n",
       " '▁of',\n",
       " '▁Maryland',\n",
       " '▁in',\n",
       " '▁',\n",
       " '1',\n",
       " '8',\n",
       " '5',\n",
       " '1',\n",
       " ',',\n",
       " '▁and',\n",
       " '▁is',\n",
       " '▁currently',\n",
       " '▁the',\n",
       " '▁most',\n",
       " '▁pop',\n",
       " 'ulous',\n",
       " '▁independent',\n",
       " '▁city',\n",
       " '▁in',\n",
       " '▁the',\n",
       " '▁nation',\n",
       " '.',\n",
       " '▁As',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁',\n",
       " '2',\n",
       " '0',\n",
       " '2',\n",
       " '0',\n",
       " '▁census',\n",
       " ',',\n",
       " '▁the',\n",
       " '▁population',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁Baltimore',\n",
       " '▁met',\n",
       " 'ropolitan',\n",
       " '▁area',\n",
       " '▁was',\n",
       " '▁estimated',\n",
       " '▁to',\n",
       " '▁be',\n",
       " '▁',\n",
       " '2',\n",
       " ',',\n",
       " '8',\n",
       " '3',\n",
       " '8',\n",
       " ',',\n",
       " '3',\n",
       " '2',\n",
       " '7',\n",
       " ',',\n",
       " '▁making',\n",
       " '▁it',\n",
       " '▁the',\n",
       " '▁',\n",
       " '2',\n",
       " '0',\n",
       " 'th',\n",
       " '-',\n",
       " 'larg',\n",
       " 'est',\n",
       " '▁met',\n",
       " 'ropolitan',\n",
       " '▁area',\n",
       " '▁in',\n",
       " '▁the',\n",
       " '▁country',\n",
       " '.',\n",
       " '▁When',\n",
       " '▁combined',\n",
       " '▁with',\n",
       " '▁the',\n",
       " '▁larger',\n",
       " '▁Washington',\n",
       " '▁met',\n",
       " 'ropolitan',\n",
       " '▁area',\n",
       " ',',\n",
       " '▁the',\n",
       " '▁Washington',\n",
       " '–',\n",
       " 'B',\n",
       " 'alt',\n",
       " 'imore',\n",
       " '▁combined',\n",
       " '▁statistical',\n",
       " '▁area',\n",
       " '▁(',\n",
       " 'C',\n",
       " 'SA',\n",
       " ')',\n",
       " '▁has',\n",
       " '▁a',\n",
       " '▁',\n",
       " '2',\n",
       " '0',\n",
       " '2',\n",
       " '0',\n",
       " '▁U',\n",
       " '.',\n",
       " 'S',\n",
       " '.',\n",
       " '▁census',\n",
       " '▁population',\n",
       " '▁of',\n",
       " '▁',\n",
       " '9',\n",
       " ',',\n",
       " '9',\n",
       " '7',\n",
       " '3',\n",
       " ',',\n",
       " '3',\n",
       " '8',\n",
       " '3',\n",
       " ',',\n",
       " '▁the',\n",
       " '▁third',\n",
       " '-',\n",
       " 'larg',\n",
       " 'est',\n",
       " '▁in',\n",
       " '▁the',\n",
       " '▁country',\n",
       " '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁#',\n",
       " ',',\n",
       " '▁a',\n",
       " '▁largest',\n",
       " '▁pop',\n",
       " 'ulous',\n",
       " '▁city',\n",
       " '▁in',\n",
       " '▁the',\n",
       " '▁U',\n",
       " '.',\n",
       " 'S',\n",
       " '.',\n",
       " '▁state',\n",
       " '▁of',\n",
       " '▁Maryland',\n",
       " ',',\n",
       " '▁It',\n",
       " '▁a',\n",
       " '▁population',\n",
       " '▁of',\n",
       " '▁',\n",
       " '6',\n",
       " '9',\n",
       " '5',\n",
       " ',',\n",
       " '7',\n",
       " '0',\n",
       " '8',\n",
       " '▁in',\n",
       " '▁the',\n",
       " '▁',\n",
       " '2',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '▁census',\n",
       " ',',\n",
       " '▁it',\n",
       " '▁is',\n",
       " '▁the',\n",
       " '▁largest',\n",
       " '3',\n",
       " '0',\n",
       " 'th',\n",
       " '▁most',\n",
       " 'most',\n",
       " '▁pop',\n",
       " 'ulous',\n",
       " '▁city',\n",
       " '▁in',\n",
       " '▁the',\n",
       " '▁United',\n",
       " '▁States',\n",
       " '▁and',\n",
       " '▁Baltimore',\n",
       " '▁is',\n",
       " '▁established',\n",
       " '▁an',\n",
       " '▁independent',\n",
       " '▁city',\n",
       " '▁by',\n",
       " '▁the',\n",
       " '▁Constitution',\n",
       " '▁of',\n",
       " '▁Maryland',\n",
       " '▁in',\n",
       " '▁',\n",
       " '1',\n",
       " '8',\n",
       " '5',\n",
       " '1',\n",
       " ',',\n",
       " '▁and',\n",
       " '▁today',\n",
       " '▁the',\n",
       " '▁the',\n",
       " '▁largest',\n",
       " '▁pop',\n",
       " 'ulous',\n",
       " '▁independent',\n",
       " '▁city',\n",
       " '▁in',\n",
       " '▁the',\n",
       " '▁United',\n",
       " '.',\n",
       " '▁As',\n",
       " '▁of',\n",
       " '▁',\n",
       " '▁',\n",
       " '2',\n",
       " '0',\n",
       " '2',\n",
       " '0',\n",
       " '▁census',\n",
       " ',',\n",
       " '▁the',\n",
       " '▁population',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁Baltimore',\n",
       " '▁met',\n",
       " 'ropolitan',\n",
       " '▁area',\n",
       " '▁was',\n",
       " '▁',\n",
       " '▁to',\n",
       " '▁be',\n",
       " '▁',\n",
       " '2',\n",
       " ',',\n",
       " '8',\n",
       " '3',\n",
       " '8',\n",
       " ',',\n",
       " '3',\n",
       " '2',\n",
       " '7',\n",
       " ',',\n",
       " '▁making',\n",
       " '▁it',\n",
       " '▁the',\n",
       " '▁',\n",
       " '2',\n",
       " '0',\n",
       " 'th',\n",
       " '▁largest',\n",
       " 'larg',\n",
       " 'est',\n",
       " '▁met',\n",
       " 'ropolitan',\n",
       " '▁area',\n",
       " '▁in',\n",
       " '▁the',\n",
       " '▁country',\n",
       " '.',\n",
       " '▁Baltimore',\n",
       " '▁combined',\n",
       " '▁with',\n",
       " '▁the',\n",
       " '▁Washington',\n",
       " '▁Baltimore',\n",
       " '▁met',\n",
       " 'ropolitan',\n",
       " '▁area',\n",
       " ',',\n",
       " '▁the',\n",
       " '▁Baltimore',\n",
       " '-',\n",
       " 'B',\n",
       " 'alt',\n",
       " 'imore',\n",
       " '▁combined',\n",
       " '▁statistical',\n",
       " '▁area',\n",
       " '▁is',\n",
       " 'C',\n",
       " 'SA',\n",
       " ')',\n",
       " '▁was',\n",
       " '▁a',\n",
       " '▁population',\n",
       " '2',\n",
       " '0',\n",
       " '2',\n",
       " '0',\n",
       " '▁population',\n",
       " '.',\n",
       " 'S',\n",
       " '.',\n",
       " '▁Census',\n",
       " '▁population',\n",
       " '▁of',\n",
       " '▁',\n",
       " '9',\n",
       " ',',\n",
       " '9',\n",
       " '4',\n",
       " '3',\n",
       " ',',\n",
       " '7',\n",
       " '2',\n",
       " '1',\n",
       " ',',\n",
       " '▁making',\n",
       " '▁fourth',\n",
       " '-',\n",
       " 'larg',\n",
       " 'est',\n",
       " '▁C',\n",
       " '▁the',\n",
       " '▁nation',\n",
       " '.',\n",
       " '▁Baltimore']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 194, 4096])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.hidden_states[-1].squeeze()[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save hidden states to disk\n",
    "\n",
    "# data_path = f\"/data/hidden_states_data/{model_name_or_path.split('/')[-1]}/offset{offset}/{attention_type}\"\n",
    "data_path = f\"/data/hidden_states_data/{output_prefix}/{model_name_or_path.split('/')[-1]}/{attention_type}\"\n",
    "\n",
    "# create dir\n",
    "Path(data_path).mkdir(parents=True, exist_ok=True)    \n",
    "    \n",
    "for layer in range(len(output.hidden_states)):\n",
    "    A = output.hidden_states[layer].detach().cpu().numpy()\n",
    "    file_name = f\"H_layer{layer}.npy\"\n",
    "    with open(os.path.join(data_path, file_name), 'wb') as f:\n",
    "        np.save(f, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
